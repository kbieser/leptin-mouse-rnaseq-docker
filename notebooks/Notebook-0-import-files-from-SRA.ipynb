{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import file from NCBI Sequence Read Archive\n",
    "\n",
    "\n",
    "**Note**: This notebook is optional. The data we need to begin our analysis is already imported into CyVerse. However, this notebook may be helpful in guiding you to import a dataset of your choice from the SRA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we need are available on the [NCBI SRA](https://www.ncbi.nlm.nih.gov/sra). The data we are working with is from an experiment with mice and described [here](https://www.ncbi.nlm.nih.gov/bioproject/353374). \n",
    "\n",
    "> **High-fat diet induced leptin and Wnt expression: RNA-sequencing and pathway analysis of mouse colonic tissue and tumors**\n",
    "\n",
    ">Obesity, an immense epidemic affecting approximately half a billion adults, has doubled in prevalence in the last several decades. Epidemiological data support that obesity due to intake of a high-fat, western diet increases the risk of colon cancer; however, the mechanisms underlying this risk remain unclear. Here, utilizing next generation RNA sequencing, we aimed to determine the high-fat diet mediated gene expression profile in mouse colon and the AOM/DSS model of colon cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get the list of accessions (sequencing runs) which is available for download here: https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP093363. We are looking for the `SraRunTable.txt` file. which can be downloaded here: https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP093363 (if you were downloading this on your own, you would click the RunInfo Table button to download this file). We have provided the file for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioSample\tDATASTORE_provider\tDATASTORE_region\tExperiment\tLibrary_Name\tLoadDate\tMBases\tMBytes\tRun\tSRA_Sample\tSample_Name\tdisease\tstrain\ttreatment\tAssay_Type\tAvgSpotLen\tBioProject\tBioSampleModel\tCenter_Name\tConsent\tDATASTORE_filetype\tInsertSize\tInstrument\tLibraryLayout\tLibrarySelection\tLibrarySource\tOrganism\tPlatform\tReleaseDate\tSRA_Study\tbiomaterial_provider\tbirth_date\tbirth_location\tcollected_by\tcollection_date\tdeath_date\tdev_stage\tgenotype\tgeo_loc_name\tisolation_source\tsample_type\tsex\ttissue\n",
      "SAMN06006115\tsra-sos\tsra-sos.public\tSRX2345613\tRD Tumor 3\t2016-11-14\t4553\t3330\tSRR5017130\tSRS1794103\tRegular Diet Tumor 3\tCancer\tC57BL/6\tMouse injected with 10 mg/1 kg AOM and had 3 separate, week long, cycles of 2.5% DSS H20 treatment within first two months of experiment.\tRNA-Seq\t101\tPRJNA353374\tModel organism or animal\tTULANE\tpublic\tsra\t0\tIllumina HiSeq 2500\tSINGLE\tother\tTRANSCRIPTOMIC\tMus musculus\tILLUMINA\t2017-01-01\tSRP093363\tDr. Suzana Savkovic: 1430 Tulane Ave., SL-79, New Orleans LA, 70112\t4-Nov-14\tJackson Laboratory\tDr. Suzana Savkovic, Tulane University\t01-Jul-2015\t1-Jul-15\tAdult\tWild-type\tUSA\tVivarium\tTissue Sample\tmale\tColon\n",
      "SAMN06006107\tncbi\t\tSRX2345614\tRD Tumor 2\t2016-11-14\t5020\t3669\tSRR5017131\tSRS1794104\tRegular Diet Tumor 2\tCancer\tC57BL/6\tMouse injected with 10 mg/1 kg AOM and had 3 separate, week long, cycles of 2.5% DSS H20 treatment within first two months of experiment.\tRNA-Seq\t101\tPRJNA353374\tModel organism or animal\tTULANE\tpublic\tsra\t0\tIllumina HiSeq 2500\tSINGLE\tother\tTRANSCRIPTOMIC\tMus musculus\tILLUMINA\t2017-01-01\tSRP093363\tDr. Suzana Savkovic: 1430 Tulane Ave., SL-79, New Orleans LA, 70112\t4-Nov-14\tJackson Laboratory\tDr. Suzana Savkovic, Tulane University\t01-Jul-2015\t1-Jul-15\tAdult\tWild-type\tUSA\tVivarium\tTissue Sample\tmale\tColon\n",
      "SAMN06006145\tncbi\t\tSRX2345615\tHFD Tumor 1\t2016-11-14\t4025\t2933\tSRR5017132\tSRS1794105\tHigh-Fat Diet Tumor 1\tObesity; Cancer\tC57BL/6\tMouse injected with 10 mg/1 kg AOM and had 3 separate, week long, cycles of 2.5% DSS H20 treatment within first two months of experiment. Also fed with 60% kcal high fat diet for 8 months/entirety of experiment.\tRNA-Seq\t101\tPRJNA353374\tModel organism or animal\tTULANE\tpublic\tsra\t0\tIllumina HiSeq 2500\tSINGLE\tother\tTRANSCRIPTOMIC\tMus musculus\tILLUMINA\t2017-01-01\tSRP093363\tDr. Suzana Savkovic: 1430 Tulane Ave., SL-79, New Orleans LA, 70112\t4-Nov-14\tJackson Laboratory\tDr. Suzana Savkovic, Tulane University\t01-Jul-2015\t1-Jul-15\tAdult\tWild-type\tUSA\tVivarium\tTissue Sample\tmale\tColon\n"
     ]
    }
   ],
   "source": [
    "head -n4 /home/gea_user/data/pre-imported/sra-files/SraRunTable.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite hard to read, but we need the `Run` column to download read data. This is column 10 in our file. We use the Unix `cut` command with the `-f` (field) option to get the 10th field (column) in our SraRunTable.txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRA_Sample\n",
      "SRS1794103\n",
      "SRS1794104\n",
      "SRS1794105\n",
      "SRS1794106\n",
      "SRS1794107\n",
      "SRS1794108\n",
      "SRS1794109\n",
      "SRS1794110\n",
      "SRS1794111\n",
      "SRS1794112\n",
      "SRS1794102\n",
      "SRS1794101\n"
     ]
    }
   ],
   "source": [
    "cut -f10 /home/gea_user/data/pre-imported/sra-files/SraRunTable.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the above lines (e.g. SRS1784103) corresponds to a file on the SRA with the read data we need for our experiment. Let's also look at the `Sample_Name` column (column 11) so we can see what these data sets are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRA_Sample\tSample_Name\n",
      "SRS1794103\tRegular Diet Tumor 3\n",
      "SRS1794104\tRegular Diet Tumor 2\n",
      "SRS1794105\tHigh-Fat Diet Tumor 1\n",
      "SRS1794106\tHigh-Fat Diet Control 3\n",
      "SRS1794107\tRegular Diet Tumor 1\n",
      "SRS1794108\tHigh-Fat Diet Control 1\n",
      "SRS1794109\tRegular Diet Control 3\n",
      "SRS1794110\tHigh-Fat Diet Control 2\n",
      "SRS1794111\tHigh-Fat Diet Tumor 3\n",
      "SRS1794112\tRegular Diet Control 1\n",
      "SRS1794102\tRegular Diet Control 2\n",
      "SRS1794101\tHigh-Fat Diet Tumor 2\n"
     ]
    }
   ],
   "source": [
    "cut -f10,11 /home/gea_user/data/pre-imported/sra-files/SraRunTable.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of possible combination of data we could study, however to keep things simple, we can focus on just the following samples \n",
    "\n",
    "|SRA_Sample\t|Sample_Name|\n",
    "|-----------|-----------|\n",
    "|SRS1794108|High-Fat Diet Control 1|\n",
    "|SRS1794110|High-Fat Diet Control 2|\n",
    "|SRS1794106|High-Fat Diet Control 3|\n",
    "|SRS1794105|High-Fat Diet Tumor 1|\n",
    "|SRS1794101|High-Fat Diet Tumor 2|\n",
    "|SRS1794111|High-Fat Diet Tumor 3|\n",
    "\n",
    "We will look at 3 replicates of RNA-Seq data from normal liver samples from mice on a high-fat diet, and 3 replicates of RNA-Seq data from liver tumor samples from mice on a high-fat diet. During the following exercises students will focus on one replicate from each of the samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this command we will get all of the \"High-Fat Diet Control\" samples and place them in a text file called `finalsamples.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut -f10,11 /home/gea_user/data/pre-imported/sra-files/SraRunTable.txt|grep \"High-Fat Diet Control\"|cut -f1 >> finalsamples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will get all of the \"High-Fat Diet Tumor\" samples and place them in a text file called `finalsamples.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut -f10,11 /home/gea_user/data/pre-imported/sra-files/SraRunTable.txt|grep \"High-Fat Diet Tumor\"|cut -f1 >> finalsamples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our `finalsamples.txt` file has the samples (SRA run numbers) we are looking for; in order to download the samples in the next steps, each run number must be on its own single line in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRS1794106\n",
      "SRS1794108\n",
      "SRS1794110\n",
      "SRS1794105\n",
      "SRS1794111\n",
      "SRS1794101\n"
     ]
    }
   ],
   "source": [
    "cat finalsamples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 (Quick) Working with pre-imported data\n",
    "\n",
    "Once we have a list of SRA accessions to import, there next 2 steps to complete the analysis would be:\n",
    "\n",
    "1. Use the `prefetch` program from [SRA Tools](https://ncbi.github.io/sra-tools/) to import the data from NCBI\n",
    "2. Use the `parallel-fastq-dump` progam ((Github Link)[https://github.com/rvalieris/parallel-fastq-dump]) to transform files from the SRA format to the fastq format. \n",
    "\n",
    "Both of these steps take a lot of time complete so we have made the output of those available to you here. There are our six fastq files as well as `small.fastq.gz` a sample file we will use in subsequent notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small.fastq.gz       SRR5017133.fastq.gz  SRR5017138.fastq.gz\n",
      "SRR5017128.fastq.gz  SRR5017135.fastq.gz\n",
      "SRR5017132.fastq.gz  SRR5017137.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "ls /home/gea_user/data/raw_data/fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can skip the rest of this notebook, unless you want to proceed with the optional steps which could take an hour or more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do two things. We are going to use the [SRA Toolkit](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc) to import the files we need from the SRA. Rather than do 19 downloads one-by-one, we can take this list of accessions and use a \"while loop\" to do the import. \n",
    "\n",
    "A [while loop](http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_09_02.html) is a bit of code, and if you are not familiar with Linux/command line it's ok to ignore this for now. \n",
    "\n",
    "We will use a while loop to read the list of run names and import them from NCBI. There are some additional options we can use to import the data more quickly, but for now we will just use the simplest options. \n",
    "\n",
    "**(Warning: These steps takes can take from 30 minutes to several hours to import - these data are pre-download on CyVerse, but we provide the code here for advanced learners who want to modify it - for example to download other SRA data)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 (Slow) SRA import and conversion to fastq format \n",
    "\n",
    "If you want to do the SRA import and conversion to fastq the cells below describe the process using our mouse data. If you were using a different dataset, you could use these commands, being careful to subsitute in your own SRA accessions and paying attention to file name changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRA Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could create your own `finalsamples.txt` file \n",
    "# This file would be a list of SRA sample accessions \n",
    "# with one accession (e.g. SRS179109) per line \n",
    "# running this cell will allow you to do the SRA import\n",
    "\n",
    "\n",
    "while read line; do prefetch $line; done<finalsamples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your files from the SRA import will be in the following location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/jovyan/ncbi/public/sra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move these files into a more convenient location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p /home/gea_user/data/raw_data && mv /home/jovyan/ncbi/public/sra/*.sra /home/gea_user/data/raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our 6 sra files in the `raw_data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/gea_user/data/raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to use another tool to convert these files into fastq format. We will covert them to a compressed (fastq.gz) format which can be directly used by Kallisto. This will take several minutes per file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p /home/gea_user/data/raw_data/fastq && cd /home/gea_user/data/raw_data/ && for file in /home/gea_user/data/raw_data/*.sra; do parallel-fastq-dump --gzip --threads 8 --outdir ./fastq/ -s $file; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have 6, zipped fastq files in our `raw_data/fastq` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/gea_user/data/raw_data/fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "We can delete the .sra files now that we have fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm /home/gea_user/data/raw_data/*.sra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
